{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The import statement will vary depending on your LLM and vector database. This is an example for OpenAI + ChromaDB\n",
    "\n",
    "from vanna.openai.openai_chat import OpenAI_Chat\n",
    "from vanna.chromadb.chromadb_vector import ChromaDB_VectorStore\n",
    "\n",
    "class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):\n",
    "    def __init__(self, config=None):\n",
    "        ChromaDB_VectorStore.__init__(self, config=config)\n",
    "        OpenAI_Chat.__init__(self, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Setting import openAIKey\n",
    "from Setting import databaseSetting\n",
    "vn = MyVanna(config={'api_key': openAIKey.Key, 'model': 'gpt-3.5-turbo'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "username=databaseSetting.username\n",
    "password=databaseSetting.password\n",
    "host=databaseSetting.host\n",
    "port=databaseSetting.port\n",
    "database='testdb'\n",
    "# 创建连接引擎\n",
    "engine = create_engine(f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path='/Users/tanghao/NUS/Internship/EverpixAnalysis/Data/External Metrics/Old Flurry Metrics.csv'\n",
    "file='Old_Flurry_Metrics'\n",
    "df = pd.read_csv(file_path)\n",
    "df.to_sql(file, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Setting import databaseSetting\n",
    "\n",
    "vn.connect_to_postgres(\n",
    "    host=databaseSetting.host,\n",
    "    dbname='testdb',\n",
    "    user=databaseSetting.username,\n",
    "    port=databaseSetting.port,\n",
    "    password=databaseSetting.password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The information schema query may need some tweaking depending on your database. This is a good starting point.\n",
    "df_information_schema = vn.run_sql(\"SELECT * FROM INFORMATION_SCHEMA.COLUMNS\")\n",
    "\n",
    "# This will break up the information schema into bite-sized chunks that can be referenced by the LLM\n",
    "plan = vn.get_training_plan_generic(df_information_schema)\n",
    "plan\n",
    "\n",
    "# If you like the plan, then uncomment this and run it to train\n",
    "# vn.train(plan=plan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
